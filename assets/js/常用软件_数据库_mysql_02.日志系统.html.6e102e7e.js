"use strict";(self.webpackChunknavyum_blog=self.webpackChunknavyum_blog||[]).push([[59365],{36995:(l,e)=>{e.A=(l,e)=>{const i=l.__vccOpts||l;for(const[l,o]of e)i[l]=o;return i}},83641:(l,e,i)=>{i.r(e),i.d(e,{comp:()=>n,data:()=>c});var o=i(6254);const d={},n=(0,i(36995).A)(d,[["render",function(l,e){return(0,o.uX)(),(0,o.CE)("div",null,e[0]||(e[0]=[(0,o.Fv)('<h2 id="bin-log-备份日志" tabindex="-1"><a class="header-anchor" href="#bin-log-备份日志"><span><code>bin log 备份日志</code></span></a></h2><ul><li>作用：<code>Server层</code>生成的日志，主要<strong>用于数据备份和主从复制</strong></li></ul><h4 id="bin-log刷盘时机" tabindex="-1"><a class="header-anchor" href="#bin-log刷盘时机"><span>bin log刷盘时机：</span></a></h4><ul><li>事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到操作系统的内核缓冲区<code>page cache</code>，最后通过<code>系统调用fsync</code>刷盘。 <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/92cb834d86e534ceb9327162eab1dac2.png" alt="Img" loading="lazy"></li></ul><h4 id="bin-log-刷盘频率控制" tabindex="-1"><a class="header-anchor" href="#bin-log-刷盘频率控制"><span>bin log 刷盘频率控制：</span></a></h4><ul><li><code>sync_binlog</code> = 0 ，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；</li><li><code>sync_binlog</code> = 1 ，表示每次提交事务都会 write，然后马上执行 fsync；</li><li><code>sync_binlog</code> = N(N&gt;1) ，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li></ul><h4 id="bin-log-格式-binlog-format" tabindex="-1"><a class="header-anchor" href="#bin-log-格式-binlog-format"><span>bin log 格式 <code>binlog_format</code>：</span></a></h4><ul><li>STATEMENT：（记录动作） <ul><li>每一条<code>修改数据的 SQL</code> 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式，binlog 可以称为逻辑日志），主从复制根据 SQL 语句重放</li><li>问题：但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；</li></ul></li><li>ROW（默认）：（记录结果） <ul><li><code>记录行数据最终被修改成什么样</code>（这种格式的日志，就不能称为逻辑日志了）</li><li>问题：但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 <code>binlog 文件过大</code></li></ul></li><li>MIXED： <ul><li>包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</li><li>折中方案</li></ul></li></ul><h2 id="redo-log-重做日志" tabindex="-1"><a class="header-anchor" href="#redo-log-重做日志"><span><code>redo log 重做日志</code></span></a></h2><ul><li><p>作用：<code>Innodb存储引擎层</code>生成的日志，实现了事务中的<strong>持久性</strong>，主要<strong>用于掉电等故障恢复</strong></p></li><li><p>常识：</p><ul><li>WAL技术 ( Write-Ahead Logging)：先写日志，再写磁盘</li><li>crash-safe：即使数据库发生异常重启，之前提交的记录都不会丢失</li></ul></li><li><p>redo log 记录内容：</p><ul><li>redo log 是<code>物理日志</code>，记录了某个数据页做了什么修改(对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了 AAA 更新)</li></ul></li><li><p>redo log 如何确保crash-safe：</p><ul><li>当系统崩溃时，即使<code>Buffer Pool</code>脏页数据没有持久化，通过已经持久化的轻量级<code>redo log</code>，将所有数据恢复到最新的状态</li></ul></li></ul><h4 id="redo-log-刷盘时机" tabindex="-1"><a class="header-anchor" href="#redo-log-刷盘时机"><span>redo log 刷盘时机：</span></a></h4><ul><li><code>log buffer</code>空间不足时（innodb_log_buffer_size）</li><li><code>事务提交时</code></li><li>后台线程不停的刷（其实是兜底逻辑）</li><li>正常关闭服务器时（异常时）</li><li>发生<code>checkpoint</code>时</li><li>其他的一些情况</li></ul><h4 id="redo-log的生成和写入" tabindex="-1"><a class="header-anchor" href="#redo-log的生成和写入"><span>redo log的生成和写入：</span></a></h4><ul><li>综述： <ul><li>事务开始执行时，可能会有多个mtr，每个mtr执行时，生成多个redo log为一组</li><li>redo log记录会按组为单位，先被写入到<code>Buffer Pool</code>中的<code>redo log buffer</code>中，这个时候更新就算完成了</li><li><code>当事务提交时</code>，再将 <code>redo log buffer</code> 持久化到磁盘中</li><li>这样就不需要等待 <code>Buffer Pool</code> 里的<code>脏页</code>数据持久化到磁盘</li><li>后台进程再将<code>Buffer Pool</code>中的用户数据刷盘处理</li></ul></li><li>既然redo log 也要刷盘，为什么不直接将用户数据刷盘? <ul><li>redo log 占用的空间非常小，用户数据可能会很大</li><li>redo log 日志是顺序IO刷盘，用户数据刷盘可能是随机IO刷盘</li></ul></li><li><code>Mini-Transaction</code>(mtr) <ul><li>对底层页面中的<code>一次原子访问的过程</code>称之为一个Mini-Transaction（mtr）</li><li>一个事务可以包含若干条语句，每一条语句其实是由若干个<code>mtr</code>组成，每一个<code>mtr</code>又可以包含若干条<code>redo</code>日志。</li><li>为什么要基于mtr做redo log记录分组： <ul><li>在恢复时，一次mtr对应的一组<code>redo log</code>需要保证事务的原子性。要么全部成功，要么都失败。</li></ul></li><li>多条redo log记录如何分组： <ul><li>分隔：组和组之间通过 type=<code>MLOG_MULTI_REC_END</code>的redo log进行分隔，组内只有一个redo log除外</li><li>通过type高位1bit，type最高位=<code>1</code>,表示是生产一条redo log记录</li></ul></li><li><code>redo log 记录结构</code>： <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/6073640f44044d698b0072f4774dc376.png" alt="Img" loading="lazy"></li><li><code>redo log 页结构</code>： <ul><li>用来存储<code>redo</code>日志的<code>页</code>称为<code>block</code>，大小为<code>512字节</code><img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/4da09f66f6c308425ac517a60d88cb27.png" alt="Img" loading="lazy"></li><li>log block body：存储redo log 记录</li><li>log block header、trailer：存储管理信息</li></ul></li><li><code>redo log buffer 结构</code>： <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/0b35d4fd38effb23fb2b9f681a0b885f.png" alt="Img" loading="lazy"><ul><li>如何确定buffer的写入位置：<code>buf_free</code>的全局变量，该变量是偏移位置，指明后续写入的<code>redo</code>日志应该写入到<code>log buffer</code>中的哪个位置</li><li>一个事务可以有多个mtr，每当一个<code>mtr</code>执行完成时，伴随该<code>mtr</code>生成的一组<code>redo</code>日志就需要被复制到<code> redo log buffer</code>；多个事务的多个mtr可以交叉写入buffer；当事务提交时，需要将所有mtr对应的<code>redo log</code>刷盘。 <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/7478dff968b6837d49ca55b320f5576d.png" alt="Img" loading="lazy"></li></ul></li></ul></li></ul><h4 id="redo-log在磁盘中的结构" tabindex="-1"><a class="header-anchor" href="#redo-log在磁盘中的结构"><span>redo log在磁盘中的结构：</span></a></h4><ul><li>redo日志文件组： <ul><li>文件名称：ib_logfile_x</li><li>大小：每个redo log文件大小：innodb_log_file_size 默认48MB,每组文件数量 innodb_log_files_in_group 默认2 <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/8cb7009677c3b76ad185111ddedeaf4e.png" alt="Img" loading="lazy"></li></ul></li><li>redo log 刷盘： <ul><li>采用循环使用的方式将redo log buffer中的数据，写到redo日志文件组里</li><li>使用checkpoint做偏移标记</li></ul></li><li><code>lsn</code>： <ul><li><code>log sequeue number</code> 日志序列号</li><li>作用：记录当前系统产生的redo log的日志量的总和</li><li>初始值：8704，就这么规定的</li><li>和buf_free全局变量的关系，lsn是结构里面的字段，buf_free是程序中的全局变量</li><li>当buf_free为12字节时，lsn = 8704 + 12</li><li>一个mtr可能会有多条redo log记录，所以对应的会有lsn起始值和结束值</li></ul></li><li><code>flushed_to_disk_lsn</code>： <ul><li>作用：表示redo log buffer中已经刷新到磁盘的序列号，用于记录下次写入buffer的偏移位置</li><li>lsn和flushed_to_disk_lsn之间的差距值就是还未写入磁盘的redo log 数据，如果值相等表示已经全部写入磁盘</li><li>和buf_next_to_write全局变量的关系，flushed_to_disk_lsn是结构里面的字段，buf_next_to_write是程序中的全局变量</li></ul></li><li><code>flush链表中的lsn</code>： <ul><li><code>oldest_modification</code>：某个页被加载到Buffer Pool后进行第一次修改，那么就将修改该页的mtr开始时对应的lsn值记为该脏页的oldest_modification</li><li><code>newest_modification</code>：某个页每次被修改，都会将修改该页的mtr结束时对应的lsn更新到newest_modification <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/0465825ba6f983b02e487aba59e0a7fe.png" alt="Img" loading="lazy"></li><li>上图解释：一次事务中，发生三次mtr <ul><li>第一次mtr起始lsn为8716，结束为8916，过程中更新了页a</li><li>第二次mtr起始lsn为8916，结束为8848，过程中更新了页c、页b</li><li>第三次mtr起始lsn9948，结束为10000，过程中更新了页b、页d</li><li>第二次mtr时，<code>在当前事务中</code>因为页b已经在buffer中，所以页b不用移动，页b的o_m不变，将该mtr结束时lsn更新给页b的n_m，页d为新页，所以会插入flush链表头部</li></ul></li><li>flush链表中的脏页顺序： <ul><li>修改发生的时间倒序，即oldest_modification</li><li>一个事务中被多次更新的页面不会重复插入到flush链表中，但是会多次更新newest_modification</li></ul></li></ul></li><li><code>checkpoint_lsn</code>： <ul><li>redo log 如何做到循环使用： <ul><li>通过checkpoint_lsn值，判断对应的脏页是否已经刷新到磁盘里，如果已经完成，则可以覆盖</li></ul></li><li>checkpoint过程： <ul><li>步骤一：计算一下当前系统中可以被覆盖的redo日志对应的lsn值最大是多少 <ul><li>从flush链表中找出当前系统中被最早修改的脏页对应的oldest_modification（因为有序性，所以一定是flush链表末尾页对应的o_m）</li></ul></li><li>步骤二：更新checkpoint_no（每次checkpoint加1）、checkpoint_lsn（最早的脏页o_m）、checkpoint_offset(lsn在日志文件中的offset)到redo日志文件组的管理信息中（当checkpoint_no的值是偶数时写到checkpoint1中，是奇数时写到checkpoint2中） <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/45bfe5c9510dc4b39bf16f5ed1ba4e83.png" alt="Img" loading="lazy"> 此时的checkpoint_lsn为页c的o_m，即8916</li></ul></li></ul></li><li>各种lsn和redo log file的关系： <ul><li>lsn：全局redo log总量</li><li>flushed_to_disk_lsn: <code>redo log buffer</code>中待写入的lsn</li><li>checkpoint_lsn: <code>flush 链表</code>中未刷入磁盘中最早的脏页对应的lsn <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/dba504c794857f9b872544c3fc7a8dc2.png" alt="Img" loading="lazy"></li></ul></li><li>查看系统的各种lsn：</li><li><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>  mysql&gt; SHOW ENGINE INNODB STATUS\\G</span></span>\n<span class="line"><span>  (...省略前面的许多状态)</span></span>\n<span class="line"><span>  LOG</span></span>\n<span class="line"><span>  ---</span></span>\n<span class="line"><span>  Log sequence number 124476971</span></span>\n<span class="line"><span>  Log flushed up to   124099769</span></span>\n<span class="line"><span>  Pages flushed up to 124052503</span></span>\n<span class="line"><span>  Last checkpoint at  124052494 ```</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li>崩溃后如何恢复： <ul><li>恢复的起始点：checkpoint_lsn</li><li>恢复的终点：redo log日志文件中，数据未写满512字节的那个block</li><li>加速恢复： <ul><li>使用hash表 <ul><li>通过space ID + page number计算散列值（详细看redo log 日志格式），散列值相同，按照生成的先后顺序通过链表法连接。这些相同的散列值，表示对同一个page的修改的redo log记录，这样可以一次性将一个页面修复好</li><li>之后就可以遍历哈希表，将页面逐个修复</li></ul></li><li>跳过已经刷新到磁盘的页 <ul><li>判断方式File Header中的FIL_PAGE_LSN（值等于newest_modification）与checkpoint_lsn比较。如果小于等于checkpoint_lsn，则表示页已经被刷到盘里，可以跳过</li></ul></li></ul></li></ul></li></ul><h4 id="binlog和redo-log区别" tabindex="-1"><a class="header-anchor" href="#binlog和redo-log区别"><span><code>binlog</code>和<code>redo log</code>区别：</span></a></h4><ol><li>日志格式</li><li>空间大小和写入方式</li><li>适用对象不同</li><li>用途不同</li></ol><h5 id="两阶段提交" tabindex="-1"><a class="header-anchor" href="#两阶段提交"><span>两阶段提交：</span></a></h5><ul><li>含义：将redo log 的写入步骤拆成了两个：<code>prepare</code> 和 <code>commit</code></li><li>作用：确保redo log 和binlog 两份日志之间的逻辑一致</li><li>redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致</li><li><code>两阶段提交</code>其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态</li></ul><h2 id="undo-log-回滚日志" tabindex="-1"><a class="header-anchor" href="#undo-log-回滚日志"><span><code>undo log 回滚日志</code>：</span></a></h2><ul><li>作用：<code>Innodb存储引擎层</code>生成的日志，实现了<code>事务中</code>的<strong>原子性</strong>，主要<strong>用于事务回滚和 MVCC</strong></li></ul><h4 id="undo-log-生成过程" tabindex="-1"><a class="header-anchor" href="#undo-log-生成过程"><span>undo log 生成过程：</span></a></h4><ul><li>在<code>事务没提交前</code>，MySQL会先记录<code>更新前的数据</code>到 undo log 日志文件里面。操作之后就可以销毁。</li><li>操作不同，需要记录到undo log的内容也不同</li></ul><h4 id="原子性场景" tabindex="-1"><a class="header-anchor" href="#原子性场景"><span>原子性场景：</span></a></h4><ul><li>当事务需要回滚时（异常回滚、主动回滚），可以利用undo log来进行回滚</li></ul><h4 id="undo-log-一致性视图实现mvcc" tabindex="-1"><a class="header-anchor" href="#undo-log-一致性视图实现mvcc"><span>undo log + 一致性视图实现MVCC：</span></a></h4><ul><li>通过undo log 的 <code>roll_pointer</code> 指针 和<code>trx_id</code>事务id构成一条记录的<code>版本链</code></li><li>通过一致性视图，可以获得当前活跃事务<code>IDs</code></li></ul><h4 id="undo-log记录的结构" tabindex="-1"><a class="header-anchor" href="#undo-log记录的结构"><span>undo log记录的结构：</span></a></h4><ul><li>不同的sql生成的undo log格式不一样 <ul><li>insert 操作 <ul><li>当我们向某个表中插入一条记录时，实际上需要向聚簇索引和所有的二级索引都插入一条记录。不过记录undo日志时，我们只需要考虑向聚簇索引的情况。（因为聚簇索引记录和二级索引记录是一一对应的，我们在回滚插入操作时，只需要知道这条记录的主键信息，然后根据主键信息做对应的undo操作）</li></ul></li><li>delete 操作 <ul><li>过程： <ul><li>阶段一：仅仅将记录的delete_mask标识位设置为1，称为delete_mask</li><li>阶段二：当该删除语句所在的事务提交之后，会有专门的线程做purge操作，真正的把记录做删除掉。（把该记录从<code>正常记录链表</code>中移除，并且加入到<code>垃圾链表</code> PAGE_FREE）</li></ul></li></ul></li><li>update 操作 <ul><li>不更新主键： <ul><li>就地更新（字段占用的存储空间大小不发生变化）： <ul><li>直接在原记录的基础上修改对应列的值</li></ul></li><li>先删除，再新增（字段占用的存储空间大小发生变化） <ul><li>先把这条旧的记录从聚簇索引页面中<code>真正删除</code>，然后再根据更新后列的值创建一条新的记录插入到页面中</li><li>优化点：空间不超过旧记录占用的空间，可以直接重用被加入到垃圾链表中的旧记录所占用的存储空间，否则需要在页面中新申请</li></ul></li></ul></li><li>更新主键： <ul><li>更新了某条记录的主键值，意味着这条记录在聚簇索引中的位置将会发生改变</li><li>过程： <ul><li>将旧记录进行delete mark操作</li><li>根据更新后各列的值创建一条新记录，<code>重新定位插入的位置</code>，并将其插入到聚簇索引</li></ul></li></ul></li></ul></li></ul></li><li>查询时 <ul><li>不详细展开</li></ul></li></ul><h4 id="undo-log和数据页的关系" tabindex="-1"><a class="header-anchor" href="#undo-log和数据页的关系"><span>undo log和数据页的关系：</span></a></h4><ul><li>通过roll_pointer关联 <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/7a54bb736234d0de9f4123f098aa3b63.png" alt="Img" loading="lazy"></li></ul><h4 id="undo-log-和事务的关系" tabindex="-1"><a class="header-anchor" href="#undo-log-和事务的关系"><span>undo log 和事务的关系：</span></a></h4><ul><li>单个事务中的Undo页面链表： <ul><li>一个事务可能包含多个语句，一个语句可能对若干条记录进行改动，而对每条记录进行改动前，都需要记录1条或2条的<code>undo日志</code></li><li>所以在一个事务执行过程中可能产生很多<code>undo日志</code>，<em><strong>这些日志可能一个页面放不下，需要放到多个页面中，这些页面就通过<code>TRX_UNDO_PAGE_NODE</code>属性连成了链表</strong></em></li><li>每个undo 页链表的首页是特殊的first undo page，存储了一些额外的管理信息<code>Undo Log Segment Header</code>，记录页链表的段信息</li></ul></li><li>单个事务中会生成哪些链表： <ul><li>undo log类型： <ul><li>同一个<code>Undo页面</code>只能存储<code>TRX_UNDO_INSERT</code>大类的undo日志<code>TRX_UNDO_UPDATE</code>大类的undo日志,这样就有了insert undo 链表和update undo 链表</li></ul></li><li>普通表和临时表： <ul><li>普通表和临时表的记录改动时产生的<code>undo日志</code>要分别记录，这样就有了<code>普通表 undo 链表</code>和<code>临时表 undo 链表</code></li></ul></li></ul></li><li>多个事务中的Undo页面链表： <ul><li>为了尽可能提高<code>undo日志</code>的写入效率，不同事务执行过程中产生的undo日志需要被写入到不同的Undo页面链表中，这样每个事务的链表完全独立 <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/82518c9575b52a222af05efb30dcf676.png" alt="Img" loading="lazy"></li></ul></li><li>事务写undo log的过程： <ul><li>一个事务在向Undo页面中写入undo日志时的方式是十分简单暴力的，就是直接往里怼，写完一条紧接着写另一条，各条undo日志之间是亲密无间的。写完一个Undo页面后，再从段里申请一个新页面，然后把这个页面插入到Undo页面链表中，继续往这个新申请的页面中写。 <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/5be8fe71f51b3e3137616de73544a694.png" alt="Img" loading="lazy"></li></ul></li></ul><h4 id="重用undo-page" tabindex="-1"><a class="header-anchor" href="#重用undo-page"><span>重用Undo page：</span></a></h4><ul><li>重复使用已提交的事务的<code>undo page</code></li><li>条件： <ul><li>该链表中只包含一个<code>Undo page</code></li><li>该<code>Undo page</code>已经使用的空间小于整个页面空间的3/4</li></ul></li></ul><h4 id="回滚段" tabindex="-1"><a class="header-anchor" href="#回滚段"><span>回滚段：</span></a></h4><ul><li>含义：在同一时刻系统里有多个事务，此时会有多个<code>Undo页面</code>链表存在。为了更好的管理这些链表，通过<code>Rollback Segment Header</code>的页面，来管理这些<code>Undo页面</code>链表。在这个页面中存放了各个<code>Undo页面</code>链表的<code>first undo page</code>的<code>页号</code>，这些<code>Undo页面</code>链表的首个页面（first undo page）在回滚段内被称为<code>undo slot</code></li><li>一个回滚段可以存放1024个<code>undo 页面 链表</code></li><li>回滚段存储在系统表的5号页面：</li><li>该页面可以存128个回滚段 <img src="https://raw.staticdn.net/Navyum/imgbed/pic/IMG/9d70f85b277c60605759bc59ff9cc61c.png" alt="Img" loading="lazy"></li></ul>',38)]))}]]),c=JSON.parse('{"path":"/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/02.%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F.html","title":"02.日志系统","lang":"zh-CN","frontmatter":{"title":"02.日志系统","date":"2025-06-17T15:20:41.000Z","author":"Navyum","icon":"fontisto:mysql","tags":["Mysql","日志系统"],"categories":["Mysql"],"article":true,"index":true,"headerDepth":2,"sticky":false,"star":true,"description":"bin log 备份日志 作用：Server层生成的日志，主要用于数据备份和主从复制 bin log刷盘时机： 事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到操作系统的内核缓冲区page cache，最后通过系统调用fsync刷盘。 Img bin log ...","head":[["meta",{"property":"og:url","content":"https://myblog.camscanner.top/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/02.%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F.html"}],["meta",{"property":"og:site_name","content":"Navyum\'s Blog"}],["meta",{"property":"og:title","content":"02.日志系统"}],["meta",{"property":"og:description","content":"bin log 备份日志 作用：Server层生成的日志，主要用于数据备份和主从复制 bin log刷盘时机： 事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到操作系统的内核缓冲区page cache，最后通过系统调用fsync刷盘。 Img bin log ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/92cb834d86e534ceb9327162eab1dac2.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-23T09:35:21.000Z"}],["meta",{"property":"article:author","content":"Navyum"}],["meta",{"property":"article:tag","content":"Mysql"}],["meta",{"property":"article:tag","content":"日志系统"}],["meta",{"property":"article:published_time","content":"2025-06-17T15:20:41.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-23T09:35:21.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"02.日志系统\\",\\"image\\":[\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/92cb834d86e534ceb9327162eab1dac2.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/6073640f44044d698b0072f4774dc376.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/4da09f66f6c308425ac517a60d88cb27.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/0b35d4fd38effb23fb2b9f681a0b885f.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/7478dff968b6837d49ca55b320f5576d.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/8cb7009677c3b76ad185111ddedeaf4e.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/0465825ba6f983b02e487aba59e0a7fe.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/45bfe5c9510dc4b39bf16f5ed1ba4e83.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/dba504c794857f9b872544c3fc7a8dc2.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/7a54bb736234d0de9f4123f098aa3b63.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/82518c9575b52a222af05efb30dcf676.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/5be8fe71f51b3e3137616de73544a694.png\\",\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/9d70f85b277c60605759bc59ff9cc61c.png\\"],\\"datePublished\\":\\"2025-06-17T15:20:41.000Z\\",\\"dateModified\\":\\"2025-06-23T09:35:21.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Navyum\\"}]}"]]},"git":{"createdTime":1749983452000,"updatedTime":1750671321000,"contributors":[{"name":"Navyum","username":"Navyum","email":"36869790+Navyum@users.noreply.github.com","commits":1,"url":"https://github.com/Navyum"},{"name":"haijun_yang","username":"haijun_yang","email":"haijun_yang@intsig.net","commits":2,"url":"https://github.com/haijun_yang"}]},"readingTime":{"minutes":12.8,"words":3839},"filePathRelative":"常用软件/数据库/mysql/02.日志系统.md","localizedDate":"2025年6月17日","excerpt":"<h2><code>bin log 备份日志</code></h2>\\n<ul>\\n<li>作用：<code>Server层</code>生成的日志，主要<strong>用于数据备份和主从复制</strong></li>\\n</ul>\\n<h4>bin log刷盘时机：</h4>\\n<ul>\\n<li>事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到操作系统的内核缓冲区<code>page cache</code>，最后通过<code>系统调用fsync</code>刷盘。\\n<img src=\\"https://raw.staticdn.net/Navyum/imgbed/pic/IMG/92cb834d86e534ceb9327162eab1dac2.png\\" alt=\\"Img\\" loading=\\"lazy\\"></li>\\n</ul>","autoDesc":true}')}}]);